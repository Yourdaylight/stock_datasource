# Stock Data Source - A-Share Financial Database

ä¸€ä¸ªå®Œæ•´çš„ A è‚¡æ•°æ®é‡‡é›†ç³»ç»Ÿï¼Œä½¿ç”¨ ClickHouse å­˜å‚¨ã€TuShare API æ•°æ®æºã€æ”¯æŒè‡ªåŠ¨åŒ–ç¼–æ’ã€‚

## ğŸ“Š é¡¹ç›®ç‰¹æ€§

- **å®Œæ•´çš„ A è‚¡æ•°æ®**ï¼šæ—¥çº¿ã€å¤æƒå› å­ã€åŸºç¡€æŒ‡æ ‡ã€æ¶¨è·Œåœã€åœå¤ç‰Œç­‰
- **7 ä¸ªç°æˆæ’ä»¶**ï¼šå¼€ç®±å³ç”¨çš„æ•°æ®é‡‡é›†æ’ä»¶
- **é«˜æ€§èƒ½å­˜å‚¨**ï¼šClickHouse åˆ—å¼æ•°æ®åº“ï¼Œæ”¯æŒ PB çº§æ•°æ®
- **è‡ªåŠ¨åŒ–ç¼–æ’**ï¼šAirflow DAG æ”¯æŒå®šæ—¶ä»»åŠ¡
- **å¤šå±‚æ•°æ®è´¨é‡**ï¼šODS â†’ DM/Fact â†’ Metadata ä¸‰å±‚æ¶æ„
- **å¹‚ç­‰æ€§ä¿è¯**ï¼šReplacingMergeTree å¼•æ“ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
- **å¯æ‰©å±•æ¶æ„**ï¼šæ˜“äºæ·»åŠ æ–°çš„æ•°æ®æºå’Œæ’ä»¶

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚

- Python 3.11+
- ClickHouse æœåŠ¡å™¨
- TuShare API Token
- uv åŒ…ç®¡ç†å·¥å…·

### å®‰è£…æ­¥éª¤

1. **å…‹éš†ä»“åº“**
```bash
git clone <repository-url>
cd stock_datasource
```

2. **å®‰è£…ä¾èµ–**
```bash
uv sync
```

3. **é…ç½®ç¯å¢ƒ**
```bash
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ TuShare Token å’Œ ClickHouse é…ç½®
```

4. **åˆå§‹åŒ–æ•°æ®åº“**
```bash
uv run cli.py init-db
```

### å¸¸ç”¨å‘½ä»¤

```bash
# å‘ç°æ‰€æœ‰æ’ä»¶
uv run python -m stock_datasource.cli_plugins discover

# åˆ—å‡ºæ‰€æœ‰æ’ä»¶
uv run python -m stock_datasource.cli_plugins list

# æŸ¥çœ‹æ’ä»¶è¯¦æƒ…
uv run python -m stock_datasource.cli_plugins info tushare_daily

# æµ‹è¯•æ’ä»¶æ•°æ®æå–
uv run python -m stock_datasource.cli_plugins test --date 20251024

# è·å–ç‰¹å®šæ—¥æœŸæ•°æ®
uv run cli.py ingest-daily --date 20251024

# æ‰¹é‡å›å¡«æ•°æ®
uv run cli.py backfill --start-date 20250101 --end-date 20251024

# æŸ¥çœ‹æ‘„å…¥çŠ¶æ€
uv run cli.py status --date 20251024

# è¿è¡Œè´¨é‡æ£€æŸ¥
uv run cli.py quality-check --date 20251024

# ç”Ÿæˆæ—¥æŠ¥å‘Š
uv run cli.py report --date 20251024

# ä¼˜åŒ–è¡¨å»é™¤é‡å¤æ•°æ®
uv run python -c "from src.stock_datasource.models.database import db_client; db_client.execute('OPTIMIZE TABLE ods_daily FINAL')"

# æ£€æŸ¥é‡å¤æ•°æ®æƒ…å†µ
uv run python -c "
from src.stock_datasource.models.database import db_client
total = db_client.execute('SELECT COUNT(*) FROM ods_daily')[0][0]
unique = db_client.execute('SELECT COUNT(DISTINCT (ts_code, trade_date)) FROM ods_daily')[0][0]
print(f'æ€»è®°å½•: {total:,}, å”¯ä¸€: {unique:,}, é‡å¤: {total-unique:,}')
"
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
stock_datasource/
â”œâ”€â”€ ğŸ“„ æ ¸å¿ƒæ–‡æ¡£
â”‚   â”œâ”€â”€ README.md                      # é¡¹ç›®æ¦‚è§ˆï¼ˆæœ¬æ–‡ä»¶ï¼‰
â”‚   â”œâ”€â”€ DEVELOPMENT_GUIDE.md           # è¯¦ç»†å¼€å‘æŒ‡å¯¼
â”‚   â”œâ”€â”€ PLUGIN_QUICK_START.md          # æ–°å»ºæ’ä»¶å¿«é€Ÿå‚è€ƒ
â”‚   â”œâ”€â”€ README_SUMMARY.md              # é¡¹ç›®æ€»ç»“å’Œå¯¼èˆª
â”‚   â””â”€â”€ BASEPLUGIN_QUICK_REFERENCE.md  # BasePlugin API å‚è€ƒ
â”‚
â”œâ”€â”€ ğŸ”§ æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ cli.py                         # CLI å‘½ä»¤å…¥å£
â”‚   â”œâ”€â”€ pyproject.toml                 # é¡¹ç›®é…ç½®å’Œä¾èµ–
â”‚   â”œâ”€â”€ uv.lock                        # ä¾èµ–é”å®šæ–‡ä»¶
â”‚   â””â”€â”€ src/stock_datasource/
â”‚       â”œâ”€â”€ core/                      # æ ¸å¿ƒæ¨¡å—
â”‚       â”‚   â”œâ”€â”€ base_plugin.py         # BasePlugin åŸºç±»
â”‚       â”‚   â”œâ”€â”€ database.py            # æ•°æ®åº“è¿æ¥
â”‚       â”‚   â””â”€â”€ plugin_manager.py      # æ’ä»¶ç®¡ç†å™¨
â”‚       â”œâ”€â”€ plugins/                   # æ•°æ®æ’ä»¶ï¼ˆ7 ä¸ªï¼‰
â”‚       â”‚   â”œâ”€â”€ tushare_daily/
â”‚       â”‚   â”œâ”€â”€ tushare_adj_factor/
â”‚       â”‚   â”œâ”€â”€ tushare_daily_basic/
â”‚       â”‚   â”œâ”€â”€ tushare_stock_basic/
â”‚       â”‚   â”œâ”€â”€ tushare_stk_limit/
â”‚       â”‚   â”œâ”€â”€ tushare_suspend_d/
â”‚       â”‚   â””â”€â”€ tushare_trade_calendar/
â”‚       â””â”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ ğŸ“Š æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ data/                          # æ•°æ®å­˜å‚¨
â”‚   â”‚   â””â”€â”€ exports/                   # å¯¼å‡ºæ•°æ®
â”‚   â””â”€â”€ logs/                          # è¿è¡Œæ—¥å¿—
â”‚
â”œâ”€â”€ ğŸ§ª æµ‹è¯•ç›®å½•
â”‚   â””â”€â”€ tests/                         # å•å…ƒæµ‹è¯•
â”‚
â”œâ”€â”€ ğŸ› ï¸ è„šæœ¬å·¥å…·
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ optimize_tables.py         # è¡¨ä¼˜åŒ–è„šæœ¬ï¼ˆå»é‡å¤æ•°æ®ï¼‰
â”‚
â”œâ”€â”€ ğŸ“š é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ .env.example                   # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â”‚   â”œâ”€â”€ .gitignore                     # Git å¿½ç•¥è§„åˆ™
â”‚   â”œâ”€â”€ .python-version                # Python ç‰ˆæœ¬
â”‚   â””â”€â”€ LICENSE                        # è®¸å¯è¯
â”‚
â””â”€â”€ ğŸ“– æ–‡æ¡£ç›®å½•
    â””â”€â”€ docs/                          # å…¶ä»–æ–‡æ¡£
```

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
TuShare API
    â†“
Plugin (Extract â†’ Validate â†’ Transform â†’ Load)
    â†“
ODS Layer (åŸå§‹æ•°æ®ï¼ŒReplacingMergeTree å¹‚ç­‰å­˜å‚¨)
    â”œâ”€ ods_daily              (æ—¥çº¿æ•°æ®ï¼ŒæŒ‰æœˆåˆ†åŒº)
    â”œâ”€ ods_adj_factor         (å¤æƒå› å­ï¼Œversion å»é‡)
    â”œâ”€ ods_daily_basic        (æ—¥çº¿åŸºç¡€æŒ‡æ ‡ï¼Œè‡ªåŠ¨åˆå¹¶)
    â”œâ”€ ods_stock_basic        (è‚¡ç¥¨åŸºç¡€ä¿¡æ¯)
    â”œâ”€ ods_stk_limit          (æ¶¨è·Œåœæ•°æ®)
    â”œâ”€ ods_suspend_d          (åœå¤ç‰Œæ•°æ®)
    â””â”€ ods_trade_calendar     (äº¤æ˜“æ—¥å†)
    â†“
DM/Fact Layer (æ¸…æ´—æ•°æ®ï¼Œç¨³å®šä¸šåŠ¡è¡¨)
    â”œâ”€ fact_daily_bar         (äº‹å®è¡¨)
    â””â”€ dim_security           (ç»´åº¦è¡¨)
    â†“
Metadata Layer (å®¡è®¡æ—¥å¿—)
    â”œâ”€ ingestion_logs         (æ‘„å…¥æ—¥å¿—)
    â”œâ”€ quality_checks         (è´¨é‡æ£€æŸ¥)
    â””â”€ schema_evolution       (Schema æ¼”å˜)
```

### ğŸ”„ å¹‚ç­‰æ€§è®¾è®¡

**ReplacingMergeTree å¼•æ“ç‰¹æ€§**ï¼š
- **å»¶è¿Ÿå»é‡**ï¼šæ’å…¥æ—¶å…è®¸é‡å¤ï¼Œåå°åˆå¹¶æ—¶è‡ªåŠ¨å»é‡
- **ç‰ˆæœ¬æ§åˆ¶**ï¼šæ¯æ¡è®°å½•åŒ…å« `version` å­—æ®µï¼ˆæ—¶é—´æˆ³ï¼‰
- **è‡ªåŠ¨ä¿ç•™æœ€æ–°**ï¼šåˆå¹¶æ—¶ä¿ç•™ version å€¼æœ€å¤§çš„è®°å½•
- **åˆ†åŒºä¼˜åŒ–**ï¼šæŒ‰æœˆåˆ†åŒº `toYYYYMM(trade_date)` æå‡æ€§èƒ½

## ğŸ“‹ 7 ä¸ªç°æˆæ’ä»¶

| æ’ä»¶ | è¡¨å | è¯´æ˜ | å‚æ•° |
|------|------|------|------|
| `tushare_daily` | `ods_daily` | æ—¥çº¿æ•°æ® | `trade_date` |
| `tushare_adj_factor` | `ods_adj_factor` | å¤æƒå› å­ | `trade_date` |
| `tushare_daily_basic` | `ods_daily_basic` | æ—¥çº¿åŸºç¡€æŒ‡æ ‡ | `trade_date` |
| `tushare_stock_basic` | `ods_stock_basic` | è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ | æ—  |
| `tushare_stk_limit` | `ods_stk_limit` | æ¶¨è·Œåœæ•°æ® | `trade_date` |
| `tushare_suspend_d` | `ods_suspend_d` | åœå¤ç‰Œæ•°æ® | `trade_date` |
| `tushare_trade_calendar` | `ods_trade_calendar` | äº¤æ˜“æ—¥å† | `start_date`, `end_date` |

## ğŸ”§ æ–°å»ºæ’ä»¶çš„å®Œæ•´æ­¥éª¤

### 1. åˆ›å»ºæ’ä»¶ç›®å½•ç»“æ„
```bash
mkdir -p src/stock_datasource/plugins/my_plugin
cd src/stock_datasource/plugins/my_plugin
touch __init__.py plugin.py extractor.py service.py config.json schema.json
```

### 2. å®ç° plugin.pyï¼ˆæ•°æ®é‡‡é›†ï¼‰
```python
from stock_datasource.core.base_plugin import BasePlugin
import pandas as pd
from .extractor import extractor

class MyPlugin(BasePlugin):
    @property
    def name(self) -> str:
        return "my_plugin"
    
    @property
    def description(self) -> str:
        return "My custom plugin"
    
    def extract_data(self, **kwargs) -> pd.DataFrame:
        """ä»æ•°æ®æºè·å–åŸå§‹æ•°æ®"""
        trade_date = kwargs.get('trade_date')
        data = extractor.extract(trade_date)
        return data
    
    def validate_data(self, data: pd.DataFrame) -> bool:
        """éªŒè¯æ•°æ®çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§"""
        if data.empty:
            return False
        return True
    
    def load_data(self, data: pd.DataFrame) -> dict:
        """å°†æ¸…æ´—åçš„æ•°æ®åŠ è½½åˆ°æ•°æ®åº“"""
        if not self.db:
            return {"status": "failed", "error": "Database not initialized"}
        
        self.db.insert_dataframe('ods_my_table', data)
        return {"status": "success", "records": len(data)}
```

### 3. å®ç° extractor.pyï¼ˆAPI è°ƒç”¨ï¼‰
```python
import pandas as pd
from stock_datasource.config.settings import settings
import tushare as ts

class Extractor:
    def __init__(self):
        self.pro = ts.pro_api(settings.TUSHARE_TOKEN)
    
    def extract(self, trade_date: str) -> pd.DataFrame:
        """ä» TuShare API è·å–æ•°æ®"""
        data = self.pro.daily(trade_date=trade_date)
        return data

extractor = Extractor()
```

### 4. å®ç° service.pyï¼ˆæŸ¥è¯¢æ¥å£ï¼‰
```python
from typing import List, Dict, Any
from stock_datasource.core.base_service import BaseService, query_method, QueryParam

class MyPluginService(BaseService):
    """Query service for my plugin data."""
    
    def __init__(self):
        super().__init__("my_plugin")
    
    @query_method(
        description="Query data by code and date range",
        params=[
            QueryParam(name="code", type="str", description="Stock code", required=True),
            QueryParam(name="start_date", type="str", description="Start date YYYYMMDD", required=True),
            QueryParam(name="end_date", type="str", description="End date YYYYMMDD", required=True),
        ]
    )
    def get_data(self, code: str, start_date: str, end_date: str) -> List[Dict[str, Any]]:
        """Query data from database."""
        query = f"""
        SELECT * FROM ods_my_table
        WHERE ts_code = '{code}'
        AND trade_date >= '{start_date}'
        AND trade_date <= '{end_date}'
        ORDER BY trade_date ASC
        """
        df = self.db.execute_query(query)
        return df.to_dict('records')
```

### 5. ç¼–å†™ config.jsonï¼ˆé…ç½®ï¼‰
```json
{
  "enabled": true,
  "rate_limit": 120,
  "timeout": 30,
  "retry_attempts": 3,
  "description": "My custom plugin",
  "parameters_schema": {
    "trade_date": {
      "type": "string",
      "format": "date",
      "required": true,
      "description": "Trade date in YYYYMMDD format"
    }
  }
}
```

### 6. ç¼–å†™ schema.jsonï¼ˆè¡¨ç»“æ„ï¼‰
```json
{
  "table_name": "ods_my_table",
  "table_type": "ods",
  "columns": [
    {"name": "ts_code", "data_type": "String", "nullable": false},
    {"name": "trade_date", "data_type": "Date", "nullable": false},
    {"name": "version", "data_type": "UInt64", "nullable": false},
    {"name": "_ingested_at", "data_type": "DateTime", "nullable": false}
  ],
  "partition_by": "toYYYYMM(trade_date)",
  "order_by": ["ts_code", "trade_date"],
  "engine": "ReplacingMergeTree"
}
```

### 7. æ³¨å†Œæ’ä»¶ (__init__.py)
```python
from .plugin import MyPlugin
from .service import MyPluginService

__all__ = ["MyPlugin", "MyPluginService"]
```

### 8. æµ‹è¯•éªŒè¯
```bash
# å‘ç°æ’ä»¶
uv run python -m stock_datasource.cli_plugins discover

# æŸ¥çœ‹æ’ä»¶è¯¦æƒ…
uv run python -m stock_datasource.cli_plugins info my_plugin

# æµ‹è¯•æ•°æ®æå–
uv run python -m stock_datasource.cli_plugins test --plugin my_plugin --date 20251024
```

## âš ï¸ æ–°å»ºæ’ä»¶çš„æ³¨æ„äº‹é¡¹

### âœ… å¿…é¡»éµå®ˆ

- **å®ç°ä¸‰ä¸ªå¿…éœ€æ–¹æ³•**ï¼š`extract_data()`ã€`validate_data()`ã€`load_data()`
- **è¿”å›æ­£ç¡®çš„ç±»å‹**ï¼š`extract_data()` å¿…é¡»è¿”å› `pd.DataFrame`
- **æ·»åŠ ç³»ç»Ÿåˆ—**ï¼š`version` å’Œ `_ingested_at`
- **ä½¿ç”¨ logger**ï¼šä½¿ç”¨ `self.logger` è®°å½•æ—¥å¿—
- **å¤„ç†å¼‚å¸¸**ï¼šæ•è·å¹¶å¤„ç†æ‰€æœ‰å¼‚å¸¸æƒ…å†µ

### âŒ å¸¸è§é”™è¯¯

- âŒ åœ¨ `extract()` ä¸­è¿›è¡Œæ•°æ®è½¬æ¢ï¼ˆåº”åœ¨ `transform()` ä¸­ï¼‰
- âŒ å¿½ç•¥å¼‚å¸¸ï¼Œè®©å…¶ä¼ æ’­åˆ°ä¸Šå±‚
- âŒ è·³è¿‡æ•°æ®éªŒè¯
- âŒ è¿”å› None æˆ–å…¶ä»–é DataFrame ç±»å‹
- âŒ ç¡¬ç¼–ç é…ç½®å€¼

## ğŸ“š æ–‡æ¡£å¯¼èˆª

| æ–‡æ¡£ | ç”¨é€” | é€‚åˆäººç¾¤ |
|------|------|---------|
| `README.md` | é¡¹ç›®æ¦‚è§ˆå’Œå¿«é€Ÿå¼€å§‹ | æ‰€æœ‰äºº |
| `DEVELOPMENT_GUIDE.md` | è¯¦ç»†çš„å¼€å‘æŒ‡å¯¼ | å¼€å‘è€… |
| `PLUGIN_QUICK_START.md` | æ–°å»ºæ’ä»¶å¿«é€Ÿå‚è€ƒ | æ–°æ‰‹å¼€å‘è€… |
| `README_SUMMARY.md` | é¡¹ç›®æ€»ç»“å’Œå¯¼èˆª | é¡¹ç›®ç®¡ç†è€… |
| `BASEPLUGIN_QUICK_REFERENCE.md` | BasePlugin API å‚è€ƒ | API å¼€å‘è€… |

## ğŸ” ç¯å¢ƒé…ç½®

### ç¯å¢ƒå˜é‡

| å˜é‡ | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `TUSHARE_TOKEN` | TuShare API Token | å¿…éœ€ |
| `CLICKHOUSE_HOST` | ClickHouse æœåŠ¡å™¨åœ°å€ | localhost |
| `CLICKHOUSE_PORT` | ClickHouse æœåŠ¡å™¨ç«¯å£ | 9000 |
| `CLICKHOUSE_DATABASE` | ClickHouse æ•°æ®åº“å | stock_datasource |
| `LOG_LEVEL` | æ—¥å¿—çº§åˆ« | INFO |

## ğŸ“Š æ•°æ®ç»Ÿè®¡

- **æ—¶é—´èŒƒå›´**ï¼š2025-01-01 è‡³ 2025-10-24ï¼ˆ195 ä¸ªäº¤æ˜“æ—¥ï¼‰
- **è‚¡ç¥¨æ•°é‡**ï¼š~5,400 åª A è‚¡
- **æ•°æ®è¡¨**ï¼š7 ä¸ª ODS è¡¨ + 2 ä¸ª Fact è¡¨ + 1 ä¸ª Dim è¡¨
- **æ€»è®°å½•æ•°**ï¼š~1.2 äº¿æ¡ï¼ˆæ¯æ—¥ ~600 ä¸‡æ¡ï¼‰

## ğŸŒ HTTP Server ä¸ MCP Server æ¥å£è‡ªåŠ¨ç”Ÿæˆ

### æ¶æ„è¯´æ˜

é¡¹ç›®é‡‡ç”¨**ç»Ÿä¸€çš„ Service å±‚è®¾è®¡**ï¼Œé€šè¿‡æ¯ä¸ªæ’ä»¶çš„ `service.py` ç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ•°æ®æŸ¥è¯¢é€»è¾‘ï¼š

```
plugins/tushare_daily/
â”œâ”€â”€ plugin.py              (æ•°æ®é‡‡é›†ï¼šExtract â†’ Validate â†’ Load)
â”œâ”€â”€ extractor.py           (API è°ƒç”¨é€»è¾‘)
â”œâ”€â”€ service.py             (æŸ¥è¯¢æ¥å£ï¼šå®šä¹‰ @query_method)
â”œâ”€â”€ config.json            (æ’ä»¶é…ç½®)
â””â”€â”€ schema.json            (è¡¨ç»“æ„å®šä¹‰)
     â”‚
     â””â”€â†’ ServiceGenerator (è‡ªåŠ¨ç”Ÿæˆ)
          â”œâ”€â”€ ç”Ÿæˆ HTTP è·¯ç”± (FastAPI)
          â””â”€â”€ ç”Ÿæˆ MCP å·¥å…·å®šä¹‰
               â”‚
               â”œâ”€â†’ HTTP Server (http_server.py)
               â”‚    â””â”€â”€ æš´éœ² REST API ç«¯ç‚¹
               â”‚
               â””â”€â†’ MCP Server (mcp_server.py)
                    â””â”€â”€ æš´éœ² MCP å·¥å…·æ¥å£
```

**å…³é”®ç‰¹æ€§**ï¼š
- **å•ä¸€æ•°æ®æº**ï¼šæ‰€æœ‰æŸ¥è¯¢é€»è¾‘åœ¨ `service.py` ä¸­å®šä¹‰ä¸€æ¬¡
- **è‡ªåŠ¨ç”Ÿæˆ**ï¼šHTTP è·¯ç”±å’Œ MCP å·¥å…·è‡ªåŠ¨ä» Service æ–¹æ³•ç”Ÿæˆ
- **å…ƒæ•°æ®é©±åŠ¨**ï¼šé€šè¿‡ `@query_method` è£…é¥°å™¨å®šä¹‰å‚æ•°å’Œæè¿°
- **ä»£ç å¤ç”¨**ï¼šHTTP å’Œ MCP å…±äº«ç›¸åŒçš„ä¸šåŠ¡é€»è¾‘
- **åŠ¨æ€å‘ç°**ï¼šè‡ªåŠ¨å‘ç°æ‰€æœ‰æ’ä»¶çš„ Service ç±»

### æ•°æ®æµå‘

```
å®¢æˆ·ç«¯è¯·æ±‚
    â”‚
    â”œâ”€â†’ HTTP è¯·æ±‚ â†’ HTTP Server â†’ ServiceGenerator â†’ TuShareDailyService.get_daily_data() â†’ ClickHouse
    â”‚
    â””â”€â†’ MCP è¯·æ±‚ â†’ MCP Server â†’ ServiceGenerator â†’ TuShareDailyService.get_daily_data() â†’ ClickHouse
```

---

## ğŸš€ HTTP æœåŠ¡å™¨ä½¿ç”¨

### å¯åŠ¨ HTTP æœåŠ¡å™¨

```bash
# æ–¹å¼ 1ï¼šä½¿ç”¨ uv
uv run python -m stock_datasource.services.http_server

# æ–¹å¼ 2ï¼šä½¿ç”¨ uvicorn
uvicorn stock_datasource.services.http_server:app --host 0.0.0.0 --port 8000
```

### HTTP è¯·æ±‚ç¤ºä¾‹

```bash
# æŸ¥è¯¢ç‰¹å®šè‚¡ç¥¨çš„æ—¥çº¿æ•°æ®
curl -X POST http://localhost:8000/api/tushare_daily/get_daily_data \
  -H "Content-Type: application/json" \
  -d '{
    "code": "000001.SZ",
    "start_date": "20250101",
    "end_date": "20251024"
  }'

# æŸ¥è¯¢æœ€æ–°æ—¥çº¿æ•°æ®
curl -X POST http://localhost:8000/api/tushare_daily/get_latest_daily \
  -H "Content-Type: application/json" \
  -d '{
    "codes": ["000001.SZ", "000002.SZ"],
    "limit": 10
  }'
```

### HTTP è·¯ç”±è‡ªåŠ¨ç”Ÿæˆ

HTTP Server ä¼šè‡ªåŠ¨ä¸ºæ¯ä¸ªæ’ä»¶çš„ Service ç±»ç”Ÿæˆè·¯ç”±ï¼š
- è·¯ç”±å‰ç¼€ï¼š`/api/{plugin_name}`
- æ–¹æ³•è·¯ç”±ï¼š`/api/{plugin_name}/{method_name}`
- è¯·æ±‚æ–¹å¼ï¼šPOST
- è¯·æ±‚ä½“ï¼šJSON æ ¼å¼çš„å‚æ•°

---

## ğŸ”Œ MCP æœåŠ¡å™¨ä½¿ç”¨

MCP Server ä¼šè‡ªåŠ¨ä¸ºæ¯ä¸ªæ’ä»¶çš„ Service æ–¹æ³•ç”Ÿæˆå·¥å…·

### å¯åŠ¨ MCP æœåŠ¡å™¨

```bash
# æ–¹å¼ 1ï¼šä½¿ç”¨ uv
uv run python -m stock_datasource.services.mcp_server

# æ–¹å¼ 2ï¼šç›´æ¥è¿è¡Œ
python src/stock_datasource/services/mcp_server.py
```

### MCP å®¢æˆ·ç«¯é…ç½®

åœ¨ Claude Codeã€Cursorã€Cline ç­‰ IDE ä¸­é…ç½® MCP æœåŠ¡å™¨ï¼š
```json
{
  "mcpServers": {
    "stock_datasource": {
      "url": "http://192.168.1.100:8001/messages",
      "transport": "streamable-http",
      "disabled": false
    }
  }
}

```


### HTTP æœåŠ¡å™¨ä½¿ç”¨

å¯åŠ¨ HTTP æœåŠ¡å™¨ï¼š
```bash
uvicorn stock_datasource.services.http_server:app --host 0.0.0.0 --port 8000
```

HTTP è¯·æ±‚ç¤ºä¾‹ï¼š
```bash
curl -X POST http://localhost:8000/get_latest_daily \
  -H "Content-Type: application/json" \
  -d '{"codes": "000001.SZ", "limit": 10}'
```

### MCP æœåŠ¡å™¨ä½¿ç”¨

å¯åŠ¨ MCP æœåŠ¡å™¨ï¼š
```bash
python -m stock_datasource.services.mcp_server
```

### MCP å·¥å…·è°ƒç”¨ç¤ºä¾‹

```python
# å·¥å…·åç§°æ ¼å¼ï¼š{plugin_name}_{method_name}
# ä¾‹å¦‚ï¼štushare_daily_get_daily_data

# å·¥å…·å‚æ•°ï¼ˆJSON æ ¼å¼ï¼‰ï¼š
{
  "code": "000001.SZ",
  "start_date": "20250101",
  "end_date": "20251024"
}
```

---

## ğŸ“‹ Service å®ç°ç»†èŠ‚

### Service ç±»ç»“æ„

æ¯ä¸ªæ’ä»¶çš„ `service.py` éƒ½éµå¾ªä»¥ä¸‹ç»“æ„ï¼š

```python
from stock_datasource.core.base_service import BaseService, query_method, QueryParam
from typing import List, Dict, Any

class TuShareDailyService(BaseService):
    """Query service for TuShare daily stock data."""
    
    def __init__(self):
        super().__init__("tushare_daily")
    
    @query_method(
        description="Query daily stock data by code and date range",
        params=[
            QueryParam(name="code", type="str", description="Stock code", required=True),
            QueryParam(name="start_date", type="str", description="Start date YYYYMMDD", required=True),
            QueryParam(name="end_date", type="str", description="End date YYYYMMDD", required=True),
        ]
    )
    def get_daily_data(self, code: str, start_date: str, end_date: str) -> List[Dict[str, Any]]:
        """Query daily data from database."""
        query = f"""
        SELECT * FROM ods_daily
        WHERE ts_code = '{code}'
        AND trade_date >= '{start_date}'
        AND trade_date <= '{end_date}'
        ORDER BY trade_date ASC
        """
        df = self.db.execute_query(query)
        return df.to_dict('records')
    
    @query_method(
        description="Query latest daily data for multiple stocks",
        params=[
            QueryParam(name="codes", type="list", description="List of stock codes", required=True),
            QueryParam(name="limit", type="int", description="Number of latest records", required=False, default=1),
        ]
    )
    def get_latest_daily(self, codes: List[str], limit: int = 1) -> List[Dict[str, Any]]:
        """Query latest daily data."""
        # å®ç°æŸ¥è¯¢é€»è¾‘
        pass
```

### å…³é”®ç»„ä»¶

1. **BaseService**ï¼šæä¾›åŸºç¡€åŠŸèƒ½
   - æ•°æ®åº“è¿æ¥ç®¡ç†ï¼ˆ`self.db`ï¼‰
   - æ–¹æ³•å…ƒæ•°æ®æå–ï¼ˆ`get_query_methods()`ï¼‰
   - ç±»å‹è½¬æ¢ï¼ˆ`python_type_to_json_schema()`ï¼‰

2. **@query_method è£…é¥°å™¨**ï¼šæ ‡è®°æŸ¥è¯¢æ–¹æ³•
   - é™„åŠ æè¿°ä¿¡æ¯ï¼ˆ`description`ï¼‰
   - å®šä¹‰å‚æ•°å…ƒæ•°æ®ï¼ˆ`params`ï¼‰
   - æ”¯æŒè‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£å’Œæ¥å£

3. **QueryParam æ•°æ®ç±»**ï¼šå®šä¹‰å‚æ•°å…ƒæ•°æ®
   - å‚æ•°åç§°ã€ç±»å‹ã€æè¿°
   - æ˜¯å¦å¿…éœ€ã€é»˜è®¤å€¼

4. **ServiceGenerator**ï¼šè‡ªåŠ¨ç”Ÿæˆæ¥å£
   - ä» Service æ–¹æ³•ç”Ÿæˆ HTTP è·¯ç”±
   - ä» Service æ–¹æ³•ç”Ÿæˆ MCP å·¥å…·
   - åŠ¨æ€åˆ›å»ºè¯·æ±‚/å“åº”æ¨¡å‹



## ğŸ§ª æµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
uv run pytest tests/

# è¿è¡Œç‰¹å®šæµ‹è¯•
uv run pytest tests/test_plugins.py

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
uv run pytest --cov=src tests/
```

## ğŸ› å¸¸è§é—®é¢˜

### Q: æ’ä»¶æœªè¢«å‘ç°
**A**: æ£€æŸ¥ `__init__.py` æ˜¯å¦å¯¼å‡ºäº†æ’ä»¶ç±»

### Q: Schema åŠ è½½å¤±è´¥
**A**: æ£€æŸ¥ `schema.json` æ˜¯å¦å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®

### Q: å‚æ•°å®šä¹‰ä¸ºç©º
**A**: æ£€æŸ¥ `config.json` ä¸­æ˜¯å¦æœ‰ `parameters_schema` å­—æ®µ

### Q: å¯¼å…¥é”™è¯¯
**A**: ç¡®ä¿ä½¿ç”¨ `uv run` è€Œä¸æ˜¯ç›´æ¥ `python`

### Q: æ•°æ®åº“ä¸­å­˜åœ¨é‡å¤æ•°æ®
**A**: è¿™æ˜¯ ReplacingMergeTree å¼•æ“çš„æ­£å¸¸è¡Œä¸ºï¼Œå‚è§ä¸‹æ–¹"é‡å¤æ•°æ®å¤„ç†"ç« èŠ‚

---

## ğŸ”„ é‡å¤æ•°æ®å¤„ç†

### é—®é¢˜è¯´æ˜

ç”±äºä½¿ç”¨ ClickHouse çš„ `ReplacingMergeTree` å¼•æ“ï¼Œç³»ç»Ÿé‡‡ç”¨**å»¶è¿Ÿå»é‡**æœºåˆ¶ï¼š
- âœ… **å¹‚ç­‰æ€§ä¿è¯**ï¼šç›¸åŒæ•°æ®å¤šæ¬¡æ’å…¥ä¸ä¼šå½±å“æœ€ç»ˆç»“æœ
- âš ï¸ **å»¶è¿Ÿå»é‡**ï¼šé‡å¤æ•°æ®åœ¨åå°åˆå¹¶å‰ä¼šæš‚æ—¶å­˜åœ¨
- ğŸ”§ **version å­—æ®µ**ï¼šé€šè¿‡æ—¶é—´æˆ³ç‰ˆæœ¬å·ç¡®ä¿ä¿ç•™æœ€æ–°æ•°æ®

### ç«‹å³è§£å†³é‡å¤æ•°æ®

#### 1. æ‰‹åŠ¨ä¼˜åŒ–å•ä¸ªè¡¨
```bash
# ä¼˜åŒ– ods_daily è¡¨
uv run python -c "
from src.stock_datasource.models.database import db_client
db_client.execute('OPTIMIZE TABLE ods_daily FINAL')
print('âœ… ods_daily è¡¨ä¼˜åŒ–å®Œæˆ')
"
```

#### 2. ä½¿ç”¨ä¸“ç”¨ä¼˜åŒ–è„šæœ¬ï¼ˆæ¨èï¼‰
```bash
# æ£€æŸ¥æ‰€æœ‰è¡¨çš„é‡å¤æ•°æ®çŠ¶æ€
uv run python scripts/optimize_tables.py --check

# ä¼˜åŒ–æ‰€æœ‰ ODS è¡¨
uv run python scripts/optimize_tables.py --all

# ä¼˜åŒ–æŒ‡å®šè¡¨
uv run python scripts/optimize_tables.py --table ods_daily

# è¯¦ç»†è¾“å‡ºæ¨¡å¼
uv run python scripts/optimize_tables.py --all --verbose
```

#### 3. æ‰¹é‡ä¼˜åŒ–æ‰€æœ‰ ODS è¡¨ï¼ˆæ‰‹åŠ¨ï¼‰
```bash
# ä¼˜åŒ–æ‰€æœ‰è¡¨
uv run python -c "
from src.stock_datasource.models.database import db_client

tables = ['ods_daily', 'ods_adj_factor', 'ods_daily_basic', 
          'ods_stk_limit', 'ods_suspend_d', 'ods_trade_calendar']

for table in tables:
    try:
        print(f'ä¼˜åŒ– {table}...')
        db_client.execute(f'OPTIMIZE TABLE {table} FINAL')
        print(f'âœ… {table} ä¼˜åŒ–å®Œæˆ')
    except Exception as e:
        print(f'âŒ {table} ä¼˜åŒ–å¤±è´¥: {e}')
"
```

#### 3. æ£€æŸ¥é‡å¤æ•°æ®æƒ…å†µ
```bash
# æ£€æŸ¥é‡å¤æ•°æ®ç»Ÿè®¡
uv run python -c "
from src.stock_datasource.models.database import db_client

table = 'ods_daily'  # å¯æ›¿æ¢ä¸ºå…¶ä»–è¡¨å
total = db_client.execute(f'SELECT COUNT(*) FROM {table}')[0][0]
unique = db_client.execute(f'SELECT COUNT(DISTINCT (ts_code, trade_date)) FROM {table}')[0][0]

print(f'è¡¨: {table}')
print(f'æ€»è®°å½•æ•°: {total:,}')
print(f'å”¯ä¸€è®°å½•æ•°: {unique:,}')
print(f'é‡å¤è®°å½•æ•°: {total - unique:,}')
print(f'é‡å¤ç‡: {((total - unique) / total * 100):.2f}%' if total > 0 else '0%')
"
```

### æŸ¥è¯¢æ—¶ç¡®ä¿æ— é‡å¤

å¯¹äºéœ€è¦ç¡®ä¿æ— é‡å¤æ•°æ®çš„æŸ¥è¯¢ï¼Œä½¿ç”¨ `FINAL` å…³é”®å­—ï¼š

```sql
-- æŸ¥è¯¢æ—¶è‡ªåŠ¨å»é‡
SELECT * FROM ods_daily FINAL 
WHERE trade_date = '20251025'
AND ts_code = '000001.SZ'

-- èšåˆæŸ¥è¯¢ï¼ˆæ¨èï¼Œæ€§èƒ½æ›´å¥½ï¼‰
SELECT ts_code, trade_date, 
       argMax(close, version) as close,
       argMax(vol, version) as vol
FROM ods_daily 
WHERE trade_date = '20251025'
GROUP BY ts_code, trade_date
```

### é¢„é˜²é‡å¤æ•°æ®çš„æœ€ä½³å®è·µ

#### 1. å®šæœŸè‡ªåŠ¨ä¼˜åŒ–
åœ¨ Airflow DAG ä¸­æ·»åŠ ä¼˜åŒ–ä»»åŠ¡ï¼š
```python
# æ¯æ—¥æ•°æ®æ‘„å…¥å®Œæˆåæ‰§è¡Œ
optimize_task = BashOperator(
    task_id='optimize_tables',
    bash_command='''
    uv run python -c "
    from src.stock_datasource.models.database import db_client
    db_client.execute('OPTIMIZE TABLE ods_daily FINAL')
    "
    ''',
    dag=dag
)
```

#### 2. ç›‘æ§é‡å¤ç‡
```bash
# æ·»åŠ åˆ°æ—¥å¸¸ç›‘æ§è„šæœ¬
uv run cli.py report --date 20251025 --check-duplicates
```

#### 3. è°ƒæ•´ ClickHouse é…ç½®
åœ¨ `config.xml` ä¸­ä¼˜åŒ–åˆå¹¶ç­–ç•¥ï¼š
```xml
<merge_tree>
    <parts_to_delay_insert>150</parts_to_delay_insert>
    <parts_to_throw_insert>300</parts_to_throw_insert>
    <max_delay_to_insert>1</max_delay_to_insert>
</merge_tree>
```

### æŠ€æœ¯åŸç†

**ReplacingMergeTree å·¥ä½œæœºåˆ¶**ï¼š
1. **æ’å…¥é˜¶æ®µ**ï¼šæ•°æ®ç›´æ¥æ’å…¥ï¼Œå…è®¸é‡å¤
2. **åˆå¹¶é˜¶æ®µ**ï¼šåå°è‡ªåŠ¨åˆå¹¶åˆ†ç‰‡æ—¶ï¼Œæ ¹æ® `ORDER BY` é”®å»é‡
3. **ç‰ˆæœ¬é€‰æ‹©**ï¼šä¿ç•™ `version` å­—æ®µå€¼æœ€å¤§çš„è®°å½•
4. **æŸ¥è¯¢ä¼˜åŒ–**ï¼šä½¿ç”¨ `FINAL` æˆ– `argMax` å‡½æ•°ç¡®ä¿ç»“æœå”¯ä¸€

**å¹‚ç­‰æ€§ä¿è¯**ï¼š
- ç›¸åŒçš„ `(ts_code, trade_date)` ç»„åˆè¢«è§†ä¸ºåŒä¸€æ¡è®°å½•
- æ¯æ¬¡æ’å…¥éƒ½ä¼šç”Ÿæˆæ–°çš„ `version`ï¼ˆæ—¶é—´æˆ³ï¼‰
- ç³»ç»Ÿè‡ªåŠ¨ä¿ç•™æœ€æ–°ç‰ˆæœ¬çš„æ•°æ®

## ğŸ“ è·å–å¸®åŠ©

- **å¿«é€Ÿé—®é¢˜** â†’ æŸ¥çœ‹ `PLUGIN_QUICK_START.md`
- **è¯¦ç»†æŒ‡å¯¼** â†’ æŸ¥çœ‹ `DEVELOPMENT_GUIDE.md`
- **API å‚è€ƒ** â†’ æŸ¥çœ‹ `BASEPLUGIN_QUICK_REFERENCE.md`
- **é¡¹ç›®æ€»ç»“** â†’ æŸ¥çœ‹ `README_SUMMARY.md`

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ LICENSE æ–‡ä»¶

## ğŸ¤ è´¡çŒ®

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## âœ¨ é¡¹ç›®çŠ¶æ€

âœ… **ç”Ÿäº§å°±ç»ª** - æ‰€æœ‰æ ¸å¿ƒæ–‡æ¡£å’Œä»£ç å·²å®Œæˆï¼Œå¯ä»¥å¼€å§‹æ–°å»ºæ’ä»¶å’Œåç»­å¼€å‘ï¼
